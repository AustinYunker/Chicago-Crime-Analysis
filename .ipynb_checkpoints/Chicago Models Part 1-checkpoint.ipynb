{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9bb74e8",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0e473f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set\n",
    "import warnings\n",
    "import re\n",
    "from pandas.io import gbq\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy import sparse\n",
    "#Custom Python Module with functions specifically for this project\n",
    "import ChicagoDataCleaningFunctions as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28888ccf",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c18029d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data in from Google BigQuery\n",
    "chicago_data = \"\"\"\n",
    "                    SELECT unique_key, date, primary_type, location_description, \n",
    "                            arrest, domestic, community_area, year\n",
    "                    FROM `gdac-327115.Chicago.chicago2`\n",
    "                    WHERE year >= 2011\n",
    "               \"\"\"\n",
    "chicago_data = gbq.read_gbq(chicago_data, project_id=\"gdac-327115\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in an Excel file with a one to one mapping between Chicago community areas and districts\n",
    "chicago_districts = pd.read_excel(\"ChicagoCommunityAreas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40ea4411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type can't be joined on an int\n",
    "chicago_districts.community_area = chicago_districts[\"community_area\"].astype(\"string\")\n",
    "chicago_data.community_area = chicago_data[\"community_area\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61878ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer join the two data sets\n",
    "chicago = chicago_data.merge(chicago_districts, how=\"outer\", left_on=\"community_area\", right_on=\"community_area\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65d50eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the community area variable since we have a community name variable\n",
    "chicago.drop(\"community_area\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a4ebd",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd75f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_train = chicago.loc[chicago[\"year\"] != 2021]\n",
    "chicago_test = chicago.loc[chicago[\"year\"] == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c846c8a",
   "metadata": {},
   "source": [
    "# Clean the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "233becf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Started...\n",
      "\n",
      "Successfully Cleaned Primary Type\n",
      "Successfully Imputed Location\n",
      "Successfully Cleaned Location\n",
      "Successfully Added Month Column\n",
      "Successfully Added Hour Column\n",
      "Successfully Cleaned Community\n",
      "\n",
      "Data Set Successfully Cleaned!\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "cd.chicago_data_cleaner(chicago_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142e4bea",
   "metadata": {},
   "source": [
    "# Prepare the Data for Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6dc47e",
   "metadata": {},
   "source": [
    "Since all of our variables are categorical, we'll need to one-hot-encode all of them. Also, note that we will not be using year as a feature. This is because the final test set will only use data from 2021. Future considerations could treat this problem as a time series problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35fa22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>16008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>12852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>15709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>15279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>18898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>18110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>18632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Count\n",
       "5      1  16008\n",
       "8      2  12852\n",
       "6      3  15709\n",
       "7      4  15279\n",
       "4      5  17493\n",
       "2      6  18468\n",
       "0      7  18898\n",
       "3      8  18110\n",
       "1      9  18632\n",
       "9     10   5507"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the test set contains data from the full year\n",
    "chicago_test.loc[:, \"date\"].dt.month. \\\n",
    "                                value_counts(). \\\n",
    "                                reset_index(). \\\n",
    "                                rename(columns={\"index\":\"Month\", \"date\":\"Count\"}). \\\n",
    "                                sort_values(by = \"Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f65338a",
   "metadata": {},
   "source": [
    "We are reminded that our final test set does not include the final two months of the year. Thus, when we transform the Month variable we'll have to drop the \"11\" and \"12\" columns to ensure that our training data matches up with the test data. We'll do this in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53cd08ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chicago_train(df, attribs):\n",
    "    \"\"\"\n",
    "    This function is just a convenient wrapper around the ColumnTransformer method for OneHotEncoding categorical features\n",
    "    specific to the training data\n",
    "    \n",
    "    df: DataFrame\n",
    "    attribs: Columns specified to be transformed. Expected data structure is a list\n",
    "    \n",
    "    returns: X(Sparse Matrix): y(Series)\n",
    "    \"\"\"\n",
    "    #Get a separate list for the time variables\n",
    "    date_attribs = [attribs.pop(attribs.index(\"Month\")), attribs.pop(attribs.index(\"Hour\"))]\n",
    "    \n",
    "    #One hot encode the variables\n",
    "    cat_encoder = OneHotEncoder()\n",
    "    X_sub = cat_encoder.fit_transform(df[attribs])\n",
    "    \n",
    "    #One hot encode the time variables but produce a dense matrix to drop the 11th and 12th values from month\n",
    "    cat_encoder = OneHotEncoder(sparse = False)\n",
    "    X_date = sparse.csr_matrix(np.delete(cat_encoder.fit_transform(df[date_attribs]), [10, 11], axis = 1))\n",
    "    \n",
    "    #Stack the two back together\n",
    "    X = sparse.hstack((X_sub, X_date))\n",
    "    y = (df[\"arrest\"] == True).astype(np.int)\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406d8ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chicago_test(df, attribs):\n",
    "    \"\"\"\n",
    "    This function is just a convenient wrapper around the ColumnTransformer method for OneHotEncoding categorical features\n",
    "    specific to the test data\n",
    "    \n",
    "    df: DataFrame\n",
    "    attribs: Columns specified to be transformed. Expected data structure is a list\n",
    "    \n",
    "    returns: X(Sparse Matrix): y(Series)\n",
    "    \"\"\"\n",
    "    cat_encoder = OneHotEncoder()\n",
    "    X = cat_encoder.fit_transform(df[attribs])\n",
    "    \n",
    "    y = (df[\"arrest\"] == True).astype(np.int)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfd2fd",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026db5d9",
   "metadata": {},
   "source": [
    "We'll only consider traditional models in Part 1. Part 2 will specifically use deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c3775",
   "metadata": {},
   "source": [
    "Now that we've prepared the data, we can build the models and get a baseline accuracy and f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18f089",
   "metadata": {},
   "source": [
    "Since the data is so large, we'll only consider a small random subset to fit different models quickly. Note that it is important to stratify on arrests since we have strong class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0295df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 14.1 s\n"
     ]
    }
   ],
   "source": [
    "#List of variables to use in the model\n",
    "cat_attribs = [\"primary_type\", \"location_description\", \"domestic\", \"district_name\", \"community_name\", \"Month\", \"Hour\"]\n",
    "\n",
    "#Prepare the data for modelling\n",
    "X, y = prepare_chicago_train(df = chicago_train, attribs = cat_attribs.copy())\n",
    "\n",
    "#Subset the data twice to quickly fit models\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size =.90, random_state = 42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size =.20, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29372544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225170, 181)\n",
      "(56293, 181)\n",
      "(225170,)\n",
      "(56293,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
