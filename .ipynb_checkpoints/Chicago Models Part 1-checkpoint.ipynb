{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86762a5b",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "044fcf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set\n",
    "import warnings\n",
    "import re\n",
    "from pandas.io import gbq\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "import xgboost\n",
    "import pickle\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy import sparse\n",
    "#Custom Python Module with functions specifically for this project\n",
    "import ChicagoDataCleaningFunctions as cd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0037ee2",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "803122eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the data in from Google BigQuery\n",
    "chicago_data = \"\"\"\n",
    "                    SELECT unique_key, date, primary_type, location_description, \n",
    "                            arrest, domestic, community_area, year\n",
    "                    FROM `gdac-327115.Chicago.chicago2`\n",
    "                    WHERE year >= 2011\n",
    "               \"\"\"\n",
    "chicago_data = gbq.read_gbq(chicago_data, project_id=\"gdac-327115\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3bf1f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in an Excel file with a one to one mapping between Chicago community areas and districts\n",
    "chicago_districts = pd.read_excel(\"ChicagoCommunityAreas.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0a4dcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data type can't be joined on an int\n",
    "chicago_districts.community_area = chicago_districts[\"community_area\"].astype(\"string\")\n",
    "chicago_data.community_area = chicago_data[\"community_area\"].astype(\"string\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4405893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outer join the two data sets\n",
    "chicago = chicago_data.merge(chicago_districts, how=\"outer\", left_on=\"community_area\", right_on=\"community_area\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd49ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the community area variable since we have a community name variable\n",
    "chicago.drop(\"community_area\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1635558",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "52f5bc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_train = chicago.loc[chicago[\"year\"] != 2021]\n",
    "chicago_test = chicago.loc[chicago[\"year\"] == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1f26b",
   "metadata": {},
   "source": [
    "# Clean the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e0e5c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Started...\n",
      "\n",
      "Successfully Cleaned Primary Type\n",
      "Successfully Imputed Location\n",
      "Successfully Cleaned Location\n",
      "Successfully Added Month Column\n",
      "Successfully Added Hour Column\n",
      "Successfully Cleaned Community\n",
      "\n",
      "Data Set Successfully Cleaned!\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "cd.chicago_data_cleaner(chicago_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfa4a30",
   "metadata": {},
   "source": [
    "# Prepare the Data for Modeling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85db4d4b",
   "metadata": {},
   "source": [
    "Since all of our variables are categorical, we'll need to one-hot-encode all of them. Also, note that we will not be using year as a feature. This is because the final test set will only use data from 2021. Future considerations could treat this problem as a time series problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "229a2b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>16008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>12852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>15709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>15279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>17493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>18468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>18898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>18110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>18632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>5507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Month  Count\n",
       "5      1  16008\n",
       "8      2  12852\n",
       "6      3  15709\n",
       "7      4  15279\n",
       "4      5  17493\n",
       "2      6  18468\n",
       "0      7  18898\n",
       "3      8  18110\n",
       "1      9  18632\n",
       "9     10   5507"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the test set contains data from the full year\n",
    "chicago_test.loc[:, \"date\"].dt.month. \\\n",
    "                                value_counts(). \\\n",
    "                                reset_index(). \\\n",
    "                                rename(columns={\"index\":\"Month\", \"date\":\"Count\"}). \\\n",
    "                                sort_values(by = \"Month\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fca731",
   "metadata": {},
   "source": [
    "We are reminded that our final test set does not include the final two months of the year. Thus, when we transform the Month variable we'll have to drop the \"11\" and \"12\" columns to ensure that our training data matches up with the test data. We'll do this in a function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0255b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chicago_train(df, attribs):\n",
    "    \"\"\"\n",
    "    This function is just a convenient wrapper around the ColumnTransformer method for OneHotEncoding categorical features\n",
    "    specific to the training data\n",
    "    \n",
    "    df: DataFrame\n",
    "    attribs: Columns specified to be transformed. Expected data structure is a list\n",
    "    \n",
    "    returns: X(Sparse Matrix): y(Series)\n",
    "    \"\"\"\n",
    "    #Get a separate list for the time variables\n",
    "    date_attribs = [attribs.pop(attribs.index(\"Month\")), attribs.pop(attribs.index(\"Hour\"))]\n",
    "    \n",
    "    #One hot encode the variables\n",
    "    cat_encoder = OneHotEncoder()\n",
    "    X_sub = cat_encoder.fit_transform(df[attribs])\n",
    "    \n",
    "    #One hot encode the time variables but produce a dense matrix to drop the 11th and 12th values from month\n",
    "    cat_encoder = OneHotEncoder(sparse = False)\n",
    "    X_date = sparse.csr_matrix(np.delete(cat_encoder.fit_transform(df[date_attribs]), [10, 11], axis = 1))\n",
    "    \n",
    "    #Stack the two back together\n",
    "    X = sparse.hstack((X_sub, X_date))\n",
    "    y = (df[\"arrest\"] == True).astype(np.int)\n",
    "    \n",
    "    return X, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf31e8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_chicago_test(df, attribs):\n",
    "    \"\"\"\n",
    "    This function is just a convenient wrapper around the ColumnTransformer method for OneHotEncoding categorical features\n",
    "    specific to the test data\n",
    "    \n",
    "    df: DataFrame\n",
    "    attribs: Columns specified to be transformed. Expected data structure is a list\n",
    "    \n",
    "    returns: X(Sparse Matrix): y(Series)\n",
    "    \"\"\"\n",
    "    cat_encoder = OneHotEncoder()\n",
    "    X = cat_encoder.fit_transform(df[attribs])\n",
    "    \n",
    "    y = (df[\"arrest\"] == True).astype(np.int)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7341213f",
   "metadata": {},
   "source": [
    "# Building the Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950cc903",
   "metadata": {},
   "source": [
    "We'll only consider traditional models in Part 1. Part 2 will specifically use deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57c3775",
   "metadata": {},
   "source": [
    "Now that we've prepared the data, we can build the models and get a baseline accuracy and F1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18f089",
   "metadata": {},
   "source": [
    "Since the data is so large, we'll only consider a small random subset to fit different models quickly. Note that it is important to stratify on arrests since we have strong class imbalance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9004de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of variables to use in the model\n",
    "cat_attribs = [\"primary_type\", \"location_description\", \"domestic\", \"district_name\", \"community_name\", \"Month\", \"Hour\"]\n",
    "\n",
    "#Prepare the data for modelling\n",
    "X, y = prepare_chicago_train(df = chicago_train, attribs = cat_attribs.copy())\n",
    "\n",
    "#Subset the data twice to quickly fit models\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size =.80, random_state = 42, stratify = y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size =.10, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "815181d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506634, 181)\n",
      "(56293, 181)\n",
      "(506634,)\n",
      "(56293,)\n"
     ]
    }
   ],
   "source": [
    "#Check the shapes\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb741b",
   "metadata": {},
   "source": [
    "# Baseline Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb68bd33",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2278eaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "591a98af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression 5-fold CV Baseline F1-Score: 65.31%\n",
      "Logistic Regression 5-fold CV Baseline Accuracy: 86.66%\n",
      "Wall time: 52.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_pred = cross_val_predict(log_reg, X_train, y_train, cv = 5)\n",
    "lr_cv_f1 = np.round(f1_score(y_train, y_train_pred), 4) * 100\n",
    "lr_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 4) * 100\n",
    "print(f'Logistic Regression 5-fold CV Baseline F1-Score: {lr_cv_f1:.2f}%')\n",
    "print(f'Logistic Regression 5-fold CV Baseline Accuracy: {lr_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80924b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "426441f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3e091408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes 5-fold CV Baseline F1-Score: 63.42%\n",
      "Naive Bayes 5-fold CV Baseline Accuracy: 85.42%\n",
      "Wall time: 14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Naive Bayes API expects arrays to be passed\n",
    "y_train_pred = cross_val_predict(nb_clf, X_train.toarray(), np.array(y_train), cv = 5)\n",
    "nb_cv_f1 = np.round(f1_score(y_train, y_train_pred), 4) * 100\n",
    "nb_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 4) * 100\n",
    "print(f'Naive Bayes 5-fold CV Baseline F1-Score: {nb_cv_f1:.2f}%')\n",
    "print(f'Naive Bayes 5-fold CV Baseline Accuracy: {nb_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a40fda",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99ccbb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = LinearSVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c5a802ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC 5-fold CV Baseline F1-Score: 65.69%\n",
      "Linear SVC 5-fold CV Baseline Accuracy: 86.98%\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_pred = cross_val_predict(svc_clf, X_train, y_train, cv = 5)\n",
    "svc_cv_f1 = np.round(f1_score(y_train, y_train_pred), 4) * 100\n",
    "svc_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 4) * 100\n",
    "print(f'Linear SVC 5-fold CV Baseline F1-Score: {svc_cv_f1:.2f}%')\n",
    "print(f'Linear SVC 5-fold CV Baseline Accuracy: {svc_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124ba58d",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8a2727c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators = 50, max_depth=25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12c1aa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 3-fold CV Baseline F1-Score: 66.62%\n",
      "Random Forest 3-fold CV Baseline Accuracy: 87.52%\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_pred = cross_val_predict(rf_clf, X_train, y_train, cv = 3)\n",
    "rf_cv_f1 = np.round(f1_score(y_train, y_train_pred), 5) * 100\n",
    "rf_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 5) * 100\n",
    "print(f'Random Forest 3-fold CV Baseline F1-Score: {rf_cv_f1:.2f}%')\n",
    "print(f'Random Forest 3-fold CV Baseline Accuracy: {rf_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05da09d0",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "206246fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf = xgboost.XGBClassifier(use_label_encoder=False, objective = \"binary:logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc45a247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:32:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:32:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_pred = cross_val_predict(xgb_clf, X_train, y_train, cv = 5)\n",
    "xgb_cv_f1 = np.round(f1_score(y_train, y_train_pred), 4) * 100\n",
    "xgb_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a080387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost 5-fold CV Baseline F1-Score: 68.59%\n",
      "XGBoost 5-fold CV Baseline Accuracy: 87.83%\n"
     ]
    }
   ],
   "source": [
    "print(f'XGBoost 5-fold CV Baseline F1-Score: {xgb_cv_f1:.2f}%')\n",
    "print(f'XGBoost 5-fold CV Baseline Accuracy: {xgb_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bf723",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9fb5f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_clf = LogisticRegression(max_iter = 10000)\n",
    "nb_clf = GaussianNB()\n",
    "svc_clf = LinearSVC()\n",
    "rf_clf = RandomForestClassifier(n_estimators=50, max_depth=25, random_state=42)\n",
    "xgb_clf = xgboost.XGBClassifier(use_label_encoder=False, objective = \"binary:logistic\")\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators = [(\"lr\", lr_clf), (\"nb\", nb_clf), (\"svc\", svc_clf), (\"rf\", rf_clf), (\"xgb\", xgb_clf)],\n",
    "    voting = \"hard\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "13bfaa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:45:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:48:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[17:52:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 10min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_train_pred = cross_val_predict(voting_clf, X_train.toarray(), np.array(y_train), cv = 3)\n",
    "vt_cv_f1 = np.round(f1_score(y_train, y_train_pred), 4) * 100\n",
    "vt_cv_acc = np.round(accuracy_score(y_train, y_train_pred), 4) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e564d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Ensemble 3-fold CV Baseline F1-Score: 65.75%\n",
      "Voting Ensemble 3-fold CV Baseline Accuracy: 87.14%\n"
     ]
    }
   ],
   "source": [
    "print(f'Voting Ensemble 3-fold CV Baseline F1-Score: {vt_cv_f1:.2f}%')\n",
    "print(f'Voting Ensemble 3-fold CV Baseline Accuracy: {vt_cv_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd424c7",
   "metadata": {},
   "source": [
    "### Preliminary Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec511e5",
   "metadata": {},
   "source": [
    "All six models give similar accuracy scores of 87% with Naive Bayes being a bit lower at 85%. However, the models have more variation in their F1-score. All but the Naive Bayes model have F1-scores around 66% but Naive Bayes only has an F1-score of 63%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e67b38",
   "metadata": {},
   "source": [
    "# Fine Tune the System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0ed974",
   "metadata": {},
   "source": [
    "Now that we have some preliminary results, we can go ahead and fine tune the hyparameters. Naive Bayes does not have any hyperparameters that need to be tuned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa6cac5",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c9a9d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5.191519151915192}\n",
      "0.6529097904207977\n",
      "Wall time: 2min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_distribs = {\n",
    "    \"C\" : np.linspace(0, 10, 10000),\n",
    "    }\n",
    "lr_clf = LogisticRegression(penalty = \"l2\", solver = \"lbfgs\", max_iter=100000)\n",
    "\n",
    "lr_rnd_search_cv = RandomizedSearchCV(lr_clf, param_distribs, n_iter = 15,\n",
    "                                   cv=2 ,scoring = 'f1', random_state=42, n_jobs = -1)\n",
    "\n",
    "lr_rnd_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(lr_rnd_search_cv.best_params_)\n",
    "print(lr_rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "41c89e34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.191519</td>\n",
       "      <td>0.652910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.265627</td>\n",
       "      <td>0.652906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.322832</td>\n",
       "      <td>0.652906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.426443</td>\n",
       "      <td>0.652903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.578558</td>\n",
       "      <td>0.652903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    param_C  mean_test_score\n",
       "3  5.191519         0.652910\n",
       "5  6.265627         0.652906\n",
       "9  8.322832         0.652906\n",
       "7  4.426443         0.652903\n",
       "8  5.578558         0.652903"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save the results in a dataframe\n",
    "lr_rnd_search_df = pd.DataFrame(lr_rnd_search_cv.cv_results_)\n",
    "#Rank the results by score\n",
    "lr_rnd_search_df[[\"param_C\", \"mean_test_score\"]].sort_values(by = \"mean_test_score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db891e8",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7fd6c384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 12.59191919191919}\n",
      "0.6568822542397925\n",
      "Wall time: 39min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_distribs = {\n",
    "    \"C\" : np.linspace(0.1, 15, 100),\n",
    "    }\n",
    "svc_clf = LinearSVC(max_iter=10000)\n",
    "\n",
    "svc_rnd_search_cv = RandomizedSearchCV(svc_clf, param_distribs, n_iter = 15,\n",
    "                                   cv=2 ,scoring = 'f1', random_state=42, n_jobs = -1)\n",
    "\n",
    "svc_rnd_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(svc_rnd_search_cv.best_params_)\n",
    "print(svc_rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "37acd4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.591919</td>\n",
       "      <td>0.656882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.076768</td>\n",
       "      <td>0.656882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.635354</td>\n",
       "      <td>0.656882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.872727</td>\n",
       "      <td>0.656882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.722222</td>\n",
       "      <td>0.656882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     param_C  mean_test_score\n",
       "0  12.591919         0.656882\n",
       "1   8.076768         0.656882\n",
       "2  10.635354         0.656882\n",
       "3   6.872727         0.656882\n",
       "4   6.722222         0.656882"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_rnd_search_df = pd.DataFrame(svc_rnd_search_cv.cv_results_)\n",
    "svc_rnd_search_df[[\"param_C\", \"mean_test_score\"]].sort_values(by = \"mean_test_score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea1efca",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2e7208a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 69, 'max_depth': 27}\n",
      "0.669302172076826\n",
      "Wall time: 30min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "param_distribs = {\n",
    "    \"n_estimators\": np.arange(25, 150),\n",
    "    \"max_depth\": np.arange(10, 30)\n",
    "    }\n",
    "rf_clf = RandomForestClassifier()\n",
    "\n",
    "rf_rnd_search_cv = RandomizedSearchCV(rf_clf, param_distribs, n_iter = 10,\n",
    "                                   cv=2 ,scoring = 'f1', random_state=42)\n",
    "\n",
    "rf_rnd_search_cv.fit(X_train, y_train)\n",
    "\n",
    "print(rf_rnd_search_cv.best_params_)\n",
    "print(rf_rnd_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "89b93bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "      <td>0.669302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>23</td>\n",
       "      <td>0.660949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>132</td>\n",
       "      <td>21</td>\n",
       "      <td>0.659324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>20</td>\n",
       "      <td>0.655046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>138</td>\n",
       "      <td>19</td>\n",
       "      <td>0.654621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth  mean_test_score\n",
       "5                 69              27         0.669302\n",
       "4                 38              23         0.660949\n",
       "9                132              21         0.659324\n",
       "1                 69              20         0.655046\n",
       "7                138              19         0.654621"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_rnd_search_df = pd.DataFrame(rf_rnd_search_cv.cv_results_)\n",
    "tuned_params = [\"param_n_estimators\", \"param_max_depth\", \"mean_test_score\"]\n",
    "rf_rnd_search_df[tuned_params].sort_values(by = \"mean_test_score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d536e43",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "abc229ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    \"max_depth\": [2,3,4,5,6,7],\n",
    "    \"gamma\": uniform(loc = 0.0, scale = 3),\n",
    "    \"min_child_weight\": list(range(20,51)),\n",
    "    \"colsample_bytree\": uniform(loc = 0.1, scale = 0.9),\n",
    "    \"learning_rate\": uniform(loc = 0.01, scale = 0.5),\n",
    "    \"subsample\": uniform(loc = 0.5, scale = 0.5),\n",
    "    \"reg_lambda\": uniform(loc = 0.01, scale = 3)\n",
    "    }\n",
    "rng = np.random.RandomState(42)\n",
    "n_iter = 30\n",
    "param_list = list(ParameterSampler(param_distribs, n_iter = n_iter, random_state=rng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "732cf524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 5 of 30\n",
      "Done with 10 of 30\n",
      "Done with 15 of 30\n",
      "Done with 20 of 30\n",
      "Done with 25 of 30\n",
      "Done with 30 of 30\n",
      "Wall time: 1h 15min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "eval_set = [(X_train, y_train), (X_val, y_val)]\n",
    "val_f1_score = []\n",
    "n_est = []\n",
    "counter = 1\n",
    "xgb_cf = xbg_clf = xgboost.XGBClassifier(n_estimators = 1000, use_label_encoder=False, objective = \"binary:logistic\")\n",
    "\n",
    "for params in param_list:\n",
    "    xgb_cf.set_params(**params)\n",
    "    xgb_cf.fit(X_train, y_train, eval_set=eval_set, eval_metric = \"auc\", verbose = False, early_stopping_rounds = 20)\n",
    "    val_set_preds = xgb_cf.predict(X_val)\n",
    "    val_f1_score.append(f1_score(y_val, val_set_preds))\n",
    "    n_est.append(int(xgb_cf.get_booster().attributes()[\"best_ntree_limit\"]))\n",
    "    if counter % 5 == 0:\n",
    "        print(f'Done with {counter} of {n_iter}')\n",
    "    counter += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e1a6c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colsample_bytree</th>\n",
       "      <th>gamma</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>min_child_weight</th>\n",
       "      <th>reg_lambda</th>\n",
       "      <th>subsample</th>\n",
       "      <th>Validation F1-Score</th>\n",
       "      <th>N Estimators</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.451955</td>\n",
       "      <td>0.546708</td>\n",
       "      <td>0.387681</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.633825</td>\n",
       "      <td>0.783850</td>\n",
       "      <td>0.688001</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.699330</td>\n",
       "      <td>1.773893</td>\n",
       "      <td>0.147361</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1.158781</td>\n",
       "      <td>0.985856</td>\n",
       "      <td>0.686650</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.393887</td>\n",
       "      <td>1.711332</td>\n",
       "      <td>0.270417</td>\n",
       "      <td>7</td>\n",
       "      <td>27</td>\n",
       "      <td>2.543602</td>\n",
       "      <td>0.873660</td>\n",
       "      <td>0.686186</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.225398</td>\n",
       "      <td>1.813252</td>\n",
       "      <td>0.279921</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2.838561</td>\n",
       "      <td>0.799433</td>\n",
       "      <td>0.686104</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.278958</td>\n",
       "      <td>2.134026</td>\n",
       "      <td>0.405088</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2.788903</td>\n",
       "      <td>0.825539</td>\n",
       "      <td>0.685971</td>\n",
       "      <td>472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    colsample_bytree     gamma  learning_rate  max_depth  min_child_weight  \\\n",
       "7           0.451955  0.546708       0.387681          7                25   \n",
       "14          0.699330  1.773893       0.147361          4                20   \n",
       "9           0.393887  1.711332       0.270417          7                27   \n",
       "17          0.225398  1.813252       0.279921          6                23   \n",
       "12          0.278958  2.134026       0.405088          4                24   \n",
       "\n",
       "    reg_lambda  subsample  Validation F1-Score  N Estimators  \n",
       "7     0.633825   0.783850             0.688001           195  \n",
       "14    1.158781   0.985856             0.686650           995  \n",
       "9     2.543602   0.873660             0.686186           336  \n",
       "17    2.838561   0.799433             0.686104           352  \n",
       "12    2.788903   0.825539             0.685971           472  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_param_search_df = pd.DataFrame(param_list)\n",
    "xgb_param_search_df[\"Validation F1-Score\"] = val_f1_score\n",
    "xgb_param_search_df[\"N Estimators\"] = n_est\n",
    "xgb_param_search_df.sort_values(by=\"Validation F1-Score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7c4b5c",
   "metadata": {},
   "source": [
    "# Final Test Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44623d3a",
   "metadata": {},
   "source": [
    "### Prepare the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "678072c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_key</th>\n",
       "      <th>date</th>\n",
       "      <th>primary_type</th>\n",
       "      <th>location_description</th>\n",
       "      <th>arrest</th>\n",
       "      <th>domestic</th>\n",
       "      <th>year</th>\n",
       "      <th>district_name</th>\n",
       "      <th>community_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>12460789</td>\n",
       "      <td>2021-08-23 12:00:00+00:00</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>Far Southeast</td>\n",
       "      <td>RIVERDALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>12493102</td>\n",
       "      <td>2021-09-25 07:00:00+00:00</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>Far Southeast</td>\n",
       "      <td>RIVERDALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>26214</td>\n",
       "      <td>2021-08-17 02:31:00+00:00</td>\n",
       "      <td>HOMICIDE</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>Far Southeast</td>\n",
       "      <td>RIVERDALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>12496804</td>\n",
       "      <td>2021-09-25 14:00:00+00:00</td>\n",
       "      <td>SEX OFFENSE</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>Far Southeast</td>\n",
       "      <td>RIVERDALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>12380276</td>\n",
       "      <td>2021-05-30 17:30:00+00:00</td>\n",
       "      <td>OTHER OFFENSE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2021</td>\n",
       "      <td>Far Southeast</td>\n",
       "      <td>RIVERDALE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     unique_key                      date        primary_type  \\\n",
       "71     12460789 2021-08-23 12:00:00+00:00  DECEPTIVE PRACTICE   \n",
       "175    12493102 2021-09-25 07:00:00+00:00  DECEPTIVE PRACTICE   \n",
       "262       26214 2021-08-17 02:31:00+00:00            HOMICIDE   \n",
       "263    12496804 2021-09-25 14:00:00+00:00         SEX OFFENSE   \n",
       "298    12380276 2021-05-30 17:30:00+00:00       OTHER OFFENSE   \n",
       "\n",
       "    location_description  arrest  domestic  year  district_name community_name  \n",
       "71             RESIDENCE   False     False  2021  Far Southeast      RIVERDALE  \n",
       "175            RESIDENCE   False     False  2021  Far Southeast      RIVERDALE  \n",
       "262               STREET   False     False  2021  Far Southeast      RIVERDALE  \n",
       "263            APARTMENT   False     False  2021  Far Southeast      RIVERDALE  \n",
       "298            RESIDENCE   False     False  2021  Far Southeast      RIVERDALE  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chicago_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "359f92a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key                0\n",
       "date                      0\n",
       "primary_type              0\n",
       "location_description    536\n",
       "arrest                    0\n",
       "domestic                  0\n",
       "year                      0\n",
       "district_name             0\n",
       "community_name            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the number of missing values\n",
    "chicago_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e9127e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Started...\n",
      "\n",
      "Successfully Cleaned Primary Type\n",
      "Successfully Imputed Location\n",
      "Successfully Cleaned Location\n",
      "Successfully Added Month Column\n",
      "Successfully Added Hour Column\n",
      "Successfully Cleaned Community\n",
      "\n",
      "Data Set Successfully Cleaned!\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "#Clean the test data\n",
    "cd.chicago_data_cleaner(chicago_test, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "bffd7f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unique_key              0\n",
       "date                    0\n",
       "primary_type            0\n",
       "location_description    0\n",
       "arrest                  0\n",
       "domestic                0\n",
       "year                    0\n",
       "district_name           0\n",
       "community_name          0\n",
       "Month                   0\n",
       "Hour                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check to make sure there are no missing values\n",
    "chicago_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0d7925e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BATTERY                              31449\n",
       "THEFT                                29703\n",
       "CRIMINAL DAMAGE                      19376\n",
       "ASSAULT                              15809\n",
       "DECEPTIVE PRACTICE                   12884\n",
       "OTHER OFFENSE                        10806\n",
       "MOTOR VEHICLE THEFT                   7598\n",
       "WEAPONS VIOLATION                     7153\n",
       "ROBBERY                               5649\n",
       "BURGLARY                              4640\n",
       "NARCOTICS                             3387\n",
       "CRIMINAL TRESPASS                     2582\n",
       "OFFENSE INVOLVING CHILDREN            1429\n",
       "CRIMINAL SEXUAL ASSAULT               1106\n",
       "SEX OFFENSE                            794\n",
       "HOMICIDE                               639\n",
       "PUBLIC PEACE VIOLATION                 475\n",
       "ARSON                                  402\n",
       "STALKING                               266\n",
       "INTERFERENCE WITH PUBLIC OFFICER       243\n",
       "CONCEALED CARRY LICENSE VIOLATION      145\n",
       "LIQUOR LAW VIOLATION                   123\n",
       "INTIMIDATION                            92\n",
       "PROSTITUTION                            72\n",
       "KIDNAPPING                              69\n",
       "OBSCENITY                               43\n",
       "GAMBLING                                10\n",
       "HUMAN TRAFFICKING                        6\n",
       "NON-CRIMINAL                             3\n",
       "PUBLIC INDECENCY                         3\n",
       "Name: primary_type, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick look at the types of crimes in the test data\n",
    "chicago_test[\"primary_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5843d462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STREET               39909\n",
       "APARTMENT            33951\n",
       "RESIDENCE            31864\n",
       "STORE                 9426\n",
       "SIDEWALK              9276\n",
       "PARKING               5144\n",
       "ALLEY                 3710\n",
       "RESTAURANT            3376\n",
       "VEHICLE               2413\n",
       "OFFICE                2286\n",
       "GAS STATION           2261\n",
       "CTA                   2221\n",
       "OTHER                 2133\n",
       "HOSPITAL              1389\n",
       "PARK PROPERTY         1318\n",
       "SCHOOL                1015\n",
       "HOTEL                  966\n",
       "AIRPORT                740\n",
       "BANK                   627\n",
       "POLICE                 555\n",
       "CHA                    520\n",
       "BUILDING               475\n",
       "VACANT                 443\n",
       "CHURCH                 306\n",
       "SPORTS                 268\n",
       "CONSTRUCTION SITE      112\n",
       "WATER                  108\n",
       "LIBRARY                 90\n",
       "COLLEGE                 54\n",
       "Name: location_description, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick check on the different locations in the test data\n",
    "chicago_test[\"location_description\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "aab427cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the training and test data for modelling\n",
    "cat_attribs = [\"primary_type\", \"location_description\", \"domestic\", \"district_name\", \"community_name\", \"Month\", \"Hour\"]\n",
    "\n",
    "X_train, y_train = prepare_chicago_train(chicago_train, attribs=cat_attribs.copy())\n",
    "X_test, y_test = prepare_chicago_test(chicago_test, attribs=cat_attribs.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "842f021b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2814636, 181)\n",
      "(2814636,)\n",
      "(156956, 181)\n",
      "(156956,)\n"
     ]
    }
   ],
   "source": [
    "#Check the shapes\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c65961",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "69038c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lr_f1 = lr_rnd_search_df[\"mean_test_score\"].argmax()\n",
    "best_C = lr_rnd_search_df.loc[max_lr_f1, \"param_C\"]\n",
    "\n",
    "log_reg = LogisticRegression(penalty = \"l2\", C = best_C, solver = \"lbfgs\", random_state=42, max_iter = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db5c45d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(log_reg, open(\"log_reg_model.sav\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa1f378f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.191519151915192, max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model with the best hyperparameters\n",
    "log_reg = pickle.load(open(\"log_reg_model.sav\", 'rb'))\n",
    "log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "738500e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5.191519151915192, max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "deda1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Test F1-Score: 54.36%\n",
      "Logistic Regression Test Accuracy Score: 89.81%\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_reg.predict(X_test)\n",
    "lr_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "lr_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'Logistic Regression Test F1-Score: {lr_test_f1:.2f}%')\n",
    "print(f'Logistic Regression Test Accuracy Score: {lr_test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f84786",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73cdae6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clf = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "462d72e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 27s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "nb_clf.fit(X_train.toarray(), np.array(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7d3dddfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Test F1-Score: 49.87%\n",
      "Naive Bayes Test Accuracy Score: 87.36%\n"
     ]
    }
   ],
   "source": [
    "y_pred = nb_clf.predict(X_test.toarray())\n",
    "nb_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "nb_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'Naive Bayes Test F1-Score: {nb_test_f1:.2f}%')\n",
    "print(f'Naive Bayes Test Accuracy Score: {nb_test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a116614",
   "metadata": {},
   "source": [
    "### Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "08eac189",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_svc_f1 = svc_rnd_search_df[\"mean_test_score\"].argmax()\n",
    "best_C = svc_rnd_search_df.loc[max_svc_f1, \"param_C\"]\n",
    "\n",
    "svc_clf = LinearSVC(penalty=\"l2\", C = best_C, max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "610d3a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(svc_clf, open(\"svc_clf_model.sav\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d981056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model with the best hyperparameters\n",
    "svc_clf = pickle.load(open(\"svc_clf_model.sav\", 'rb'))\n",
    "svc_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f6d9e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51min 16s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=12.59191919191919, max_iter=10000)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "svc_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c0d091cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Test F1-Score: 55.66%\n",
      "Linear SVC Test Accuracy Score: 90.55%\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_clf.predict(X_test)\n",
    "svc_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "svc_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'Linear SVC Test F1-Score: {svc_test_f1:.2f}%')\n",
    "print(f'Linear SVC Test Accuracy Score: {svc_test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b0f3caec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[132808,   9837],\n",
       "       [  4999,   9312]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a2f7dc",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6df39b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_rf_f1 = rf_rnd_search_df[\"mean_test_score\"].argmax()\n",
    "best_n_est = rf_rnd_search_df.loc[max_rf_f1, \"param_n_estimators\"]\n",
    "best_max_depth = rf_rnd_search_df.loc[max_rf_f1, \"param_max_depth\"]\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=best_n_est, max_depth=best_max_depth, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "80d05098",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_clf, open(\"rf_clf_model.sav\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "467e6932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=27, n_estimators=69, n_jobs=-1,\n",
       "                       random_state=42)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the model with the best hyperparameters\n",
    "rf_clf = pickle.load(open(\"rf_clf_model.sav\", 'rb'))\n",
    "rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cee8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_clf.predict(X_test)\n",
    "rf_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "rf_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'Random Forest Test F1-Score: {rf_test_f1}%')\n",
    "print(f'Random Forest Test Accuracy Score: {rf_test_acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f8320",
   "metadata": {},
   "source": [
    "### XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d68e7d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_xgb_f1 = xgb_param_search_df[\"Validation F1-Score\"].argmax()\n",
    "best_colsample = xgb_param_search_df.loc[max_xgb_f1, \"colsample_bytree\"]\n",
    "best_gamma = xgb_param_search_df.loc[max_xgb_f1, \"gamma\"]\n",
    "best_lr = xgb_param_search_df.loc[max_xgb_f1, \"learning_rate\"]\n",
    "best_max_depth = xgb_param_search_df.loc[max_xgb_f1, \"max_depth\"]\n",
    "best_min_child = xgb_param_search_df.loc[max_xgb_f1, \"min_child_weight\"]\n",
    "best_reg_lambda = xgb_param_search_df.loc[max_xgb_f1, \"reg_lambda\"]\n",
    "best_subsample = xgb_param_search_df.loc[max_xgb_f1, \"subsample\"]\n",
    "best_n_est = xgb_param_search_df.loc[max_xgb_f1, \"N Estimators\"]\n",
    "\n",
    "xgb_clf = xgboost.XGBClassifier(n_estimators=best_n_est, colsample_bytree = best_colsample, gamma = best_gamma, \n",
    "                                learning_rate=best_lr, max_depth = best_max_depth, min_child_weight=best_min_child,\n",
    "                                reg_lambda=best_reg_lambda, subsample=best_subsample,\n",
    "                                use_label_encoder=False, objective = \"binary:logistic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0e81a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(xgb_clf, open(\"xgb_clf_model.sav\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c2bd91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "              colsample_bynode=None, colsample_bytree=0.731770189531933,\n",
       "              enable_categorical=False, gamma=2.3873780083083034, gpu_id=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.45500267090878316, max_delta_step=None,\n",
       "              max_depth=5, min_child_weight=21, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=173, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, random_state=None,\n",
       "              reg_alpha=None, reg_lambda=0.291945819522607,\n",
       "              scale_pos_weight=None, subsample=0.789140070498087,\n",
       "              tree_method=None, use_label_encoder=False,\n",
       "              validate_parameters=None, verbosity=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_clf = pickle.load(open(\"xgb_clf_model.sav\", 'rb'))\n",
    "xgb_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d203c55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 2min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.731770189531933,\n",
       "              enable_categorical=False, gamma=2.3873780083083034, gpu_id=-1,\n",
       "              importance_type=None, interaction_constraints='',\n",
       "              learning_rate=0.45500267090878316, max_delta_step=0, max_depth=5,\n",
       "              min_child_weight=21, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=173, n_jobs=8, num_parallel_tree=1, predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=0.291945819522607,\n",
       "              scale_pos_weight=1, subsample=0.789140070498087,\n",
       "              tree_method='exact', use_label_encoder=False,\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "xgb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1b26ebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Test F1-Score: 57.983%\n",
      "XGBoost Test Accuracy Score: 90.892%\n"
     ]
    }
   ],
   "source": [
    "y_pred = xgb_clf.predict(X_test)\n",
    "xgb_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "xgb_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'XGBoost Test F1-Score: {xgb_test_f1}%')\n",
    "print(f'XGBoost Test Accuracy Score: {xgb_test_acc}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a8d64",
   "metadata": {},
   "source": [
    "### Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "caaf8367",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators = [(\"lr\", log_reg), (\"nb\", nb_clf), (\"svc\", svc_clf), (\"rf\", rf_clf), (\"xgb\", xgb_clf)],\n",
    "    voting = \"hard\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bd68f8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(voting_clf, open(\"voting_clf_model.sav\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d35efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf = pickle.load(open(\"voting_clf_model.sav\", 'rb'))\n",
    "voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c56937",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88d75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = voting_clf.predict(X_test)\n",
    "vt_test_f1 = np.round(f1_score(y_pred, y_test), 5) * 100\n",
    "vt_test_acc = np.round(accuracy_score(y_pred, y_test), 5) * 100\n",
    "print(f'Voting Ensemble Test F1-Score: {vt_test_f1}%')\n",
    "print(f'Voting Ensemble Accuracy Score: {vt_test_acc}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
