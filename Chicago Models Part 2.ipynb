{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d42c7e0",
   "metadata": {},
   "source": [
    "# Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a853395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "#from keras.utils import plot_model\n",
    "\n",
    "#Custom Python Module with functions specifically for this project\n",
    "import ChicagoDataCleaningFunctions as cd\n",
    "#Custom Python Module to fetch the data\n",
    "import FetchChicagoData as fc\n",
    "#Custom Python Module to prepare new crime instances\n",
    "import PrepareChicago as pc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe3d09",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9e71a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Chicago Data Started...\n",
      "\n",
      "Successfully queried Google BigQuery.\n",
      "Sucessfully read in excel file.\n",
      "Sucessfully joined Chicago districts to main data.\n",
      "Successfully dropped duplicate column\n",
      "\n",
      "Succcessfully fetched Chicago Data\n",
      "Wall time: 3min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Specify input values for fetching the data\n",
    "query = \"\"\"\n",
    "            SELECT unique_key, date, primary_type, location_description, \n",
    "                    arrest, domestic, community_area, year\n",
    "            FROM `gdac-327115.Chicago.chicago2`\n",
    "            WHERE year >= 2011\n",
    "        \"\"\"\n",
    "project_id = \"gdac-327115\"\n",
    "excel_file = \"ChicagoCommunityAreas.xlsx\"\n",
    "\n",
    "#Fetch the data\n",
    "chicago = fc.fetch_chicago_data(query, project_id, excel_file, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49b86bb",
   "metadata": {},
   "source": [
    "# Split the Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0acff222",
   "metadata": {},
   "outputs": [],
   "source": [
    "chicago_train = chicago.loc[chicago[\"year\"] != 2021]\n",
    "chicago_test = chicago.loc[chicago[\"year\"] == 2021]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7051899",
   "metadata": {},
   "source": [
    "# Clean the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80dd6eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning Started...\n",
      "\n",
      "Successfully Cleaned Primary Type\n",
      "Successfully Imputed Location\n",
      "Successfully Cleaned Location\n",
      "Successfully Added Month Column\n",
      "Successfully Added Hour Column\n",
      "Successfully Cleaned Community\n",
      "\n",
      "Data Set Successfully Cleaned!\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "cd.chicago_data_cleaner(chicago_train, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2474f5",
   "metadata": {},
   "source": [
    "# Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d0afaf",
   "metadata": {},
   "source": [
    "Since we are focusing on using deep learning techniques, we do more than just one hot encoding the variables. Instead, we'll use embeddings to encode the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "10019b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_array(df, attribs):\n",
    "    X = df[attribs].values\n",
    "    y = df[\"arrest\"].values\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f9aaad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test):\n",
    "    \"\"\"\n",
    "    This function prepares the input data by ordinal encoding each one and adding it to a list.\n",
    "    \n",
    "    X_train: Array of training features\n",
    "    X_test: Array of test features\n",
    "    \n",
    "    returns: Two lists of encoded training and test features\n",
    "    \"\"\"\n",
    "    X_train_enc, X_test_enc = list(), list()\n",
    "    # label encode each column\n",
    "    for i in range(X_train.shape[1]):\n",
    "        le = LabelEncoder()\n",
    "        le.fit(X_train[:, i])\n",
    "        # encode\n",
    "        train_enc = le.transform(X_train[:, i])\n",
    "        test_enc = le.transform(X_test[:, i])\n",
    "        # store\n",
    "        X_train_enc.append(train_enc)\n",
    "        X_test_enc.append(test_enc)\n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "493c1d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test):\n",
    "    \"\"\"\n",
    "    This function transforms the target by ordinal encoding the values. \n",
    "    \n",
    "    y_train: Array of training targets\n",
    "    y_test: Array of test targets\n",
    "    \n",
    "    returns: Two lists containing the transformed targets\n",
    "    \"\"\"\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "48cfbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the features to use\n",
    "features = [\"primary_type\", \"location_description\", \"domestic\", \"district_name\", \"community_name\", \"Month\", \"Hour\"]\n",
    "#Transform the features and targets into arrays\n",
    "X, y = data_to_array(chicago_train, features)\n",
    "#Split the data twice to quickly train preliminary models\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = .80, random_state = 42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size =.10, random_state = 42, stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e2b7384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506634, 7)\n",
      "(56293, 7)\n",
      "(506634,)\n",
      "(56293,)\n"
     ]
    }
   ],
   "source": [
    "#Check the shapes\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8912782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode the training and target features\n",
    "X_train_enc, X_val_enc = prepare_inputs(X_train, X_val)\n",
    "#Encode the training and validation targets\n",
    "y_train_enc, y_val_enc = prepare_targets(y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e307c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_to_embedding(n_embeddings, training_encodings):\n",
    "    \"\"\"\n",
    "    This function iterates through each variable and constructs and input layer and connects it to an embedding\n",
    "    layer, and stores both layers in a list. \n",
    "        \n",
    "    n_embeddings: Number of embedding dimensions\n",
    "    training_encodings: List of training features\n",
    "    \n",
    "    returns:\n",
    "        in_layers: List of input layers\n",
    "        em_layers: List of embedding layers\n",
    "    \"\"\"\n",
    "    in_layers = list()\n",
    "    em_layers = list()\n",
    "    for i in range(len(training_encodings)):\n",
    "        #Calculate the number of unique inputs\n",
    "        n_labels = len(np.unique(training_encodings[i]))\n",
    "        #Define input layer\n",
    "        in_layer = Input(shape=(1,))\n",
    "        #Define embedding layer\n",
    "        em_layer = Embedding(n_labels, n_embeddings)(in_layer)\n",
    "        #Store layers\n",
    "        in_layers.append(in_layer)\n",
    "        em_layers.append(em_layer)\n",
    "    return in_layers, em_layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18defa10",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc5b00",
   "metadata": {},
   "source": [
    "Although, no one will agree on what a \"baseline\" neural network model looks like, we can build a simple two layer model with 10 neurons in each layer using 10 as the dimension of the embeddings. The model will use the binary crossentropy loss with the adam optimizer and run for 10 epochs with a batch size of 32. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "9fe75c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layers, embed_layers = input_to_embedding(n_embeddings=10, training_encodings=X_train_enc)\n",
    "input_ = keras.layers.concatenate(em_layers)\n",
    "hidden1 = Dense(10, activation='relu')(input_)\n",
    "hidden2 = Dense(10, activation='relu')(hidden1)\n",
    "output = Dense(1, activation='sigmoid')(hidden2)\n",
    "model = Model(inputs=in_layers, outputs=output)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "62b336cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "15833/15833 - 20s - loss: 0.3075 - accuracy: 0.8790\n",
      "Epoch 2/10\n",
      "15833/15833 - 19s - loss: 0.3073 - accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "15833/15833 - 18s - loss: 0.3071 - accuracy: 0.8792\n",
      "Epoch 4/10\n",
      "15833/15833 - 17s - loss: 0.3069 - accuracy: 0.8791\n",
      "Epoch 5/10\n",
      "15833/15833 - 16s - loss: 0.3067 - accuracy: 0.8790\n",
      "Epoch 6/10\n",
      "15833/15833 - 17s - loss: 0.3066 - accuracy: 0.8793\n",
      "Epoch 7/10\n",
      "15833/15833 - 16s - loss: 0.3065 - accuracy: 0.8790\n",
      "Epoch 8/10\n",
      "15833/15833 - 16s - loss: 0.3064 - accuracy: 0.8793\n",
      "Epoch 9/10\n",
      "15833/15833 - 17s - loss: 0.3063 - accuracy: 0.8793\n",
      "Epoch 10/10\n",
      "15833/15833 - 16s - loss: 0.3062 - accuracy: 0.8793\n",
      "Wall time: 2min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e1a285cdf0>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(X_train_enc, y_train_enc, epochs=10, batch_size=32, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cadf221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Baseline Accuracy Score: 87.64%\n",
      "Model Baseline F1-Score: 68.99%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val_enc)\n",
    "y_pred = np.round(y_pred.reshape((y_pred.shape[0])))\n",
    "y_val = y_val.astype(np.int)\n",
    "model_base_acc = np.round(accuracy_score(y_pred, y_val), 4) * 100\n",
    "model_base_f1 = np.round(f1_score(y_pred, y_val), 4) * 100\n",
    "print(f\"Model Baseline Accuracy Score: {model_base_acc:.2f}%\")\n",
    "print(f\"Model Baseline F1-Score: {model_base_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11de8c9",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "087b66aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.concatenate(em_layers)\n",
    "hidden1 = Dense(10, activation='relu', kernel_initializer='he_normal')(input_)\n",
    "hidden2 = Dense(10, activation='relu', kernel_initializer='he_normal')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden10])\n",
    "output = Dense(1, activation='sigmoid')(concat)\n",
    "model = Model(inputs=in_layers, outputs=output)\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "cf436570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1980/1980 - 8s - loss: 0.3161 - accuracy: 0.8757\n",
      "Epoch 2/10\n",
      "1980/1980 - 4s - loss: 0.3095 - accuracy: 0.8783\n",
      "Epoch 3/10\n",
      "1980/1980 - 3s - loss: 0.3086 - accuracy: 0.8787\n",
      "Epoch 4/10\n",
      "1980/1980 - 4s - loss: 0.3081 - accuracy: 0.8790\n",
      "Epoch 5/10\n",
      "1980/1980 - 4s - loss: 0.3078 - accuracy: 0.8789\n",
      "Epoch 6/10\n",
      "1980/1980 - 4s - loss: 0.3074 - accuracy: 0.8792\n",
      "Epoch 7/10\n",
      "1980/1980 - 4s - loss: 0.3071 - accuracy: 0.8791\n",
      "Epoch 8/10\n",
      "1980/1980 - 3s - loss: 0.3069 - accuracy: 0.8790\n",
      "Epoch 9/10\n",
      "1980/1980 - 4s - loss: 0.3067 - accuracy: 0.8791\n",
      "Epoch 10/10\n",
      "1980/1980 - 3s - loss: 0.3066 - accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e19a5292b0>"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_enc, y_train_enc, epochs=10, batch_size=256, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "50533453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Baseline Accuracy Score: 87.62%\n",
      "Model Baseline F1-Score: 69.07%\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_val_enc)\n",
    "y_pred = np.round(y_pred.reshape((y_pred.shape[0])))\n",
    "y_val = y_val.astype(np.int)\n",
    "model_base_acc = np.round(accuracy_score(y_pred, y_val), 4) * 100\n",
    "model_base_f1 = np.round(f1_score(y_pred, y_val), 4) * 100\n",
    "print(f\"Model Baseline Accuracy Score: {model_base_acc:.2f}%\")\n",
    "print(f\"Model Baseline F1-Score: {model_base_f1:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d8e1aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e25f6d6a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Dimension value must be integer or None or have an __index__ method, got value '<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_8')>' with type '<class 'keras.engine.keras_tensor.KerasTensor'>'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-8171e9361982>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0min_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"sigmoid\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"binary_crossentropy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"adam\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m           \u001b[1;31m# Instantiate an input layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m           x = input_layer.Input(\n\u001b[0m\u001b[0;32m    209\u001b[0m               batch_shape=batch_shape, dtype=dtype, name=layer.name + '_input')\n\u001b[0;32m    210\u001b[0m           \u001b[1;31m# This will build the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    384\u001b[0m     input_layer_config.update(\n\u001b[0;32m    385\u001b[0m         {'batch_size': batch_size, 'input_shape': shape})\n\u001b[1;32m--> 386\u001b[1;33m   \u001b[0minput_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInputLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minput_layer_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    388\u001b[0m   \u001b[1;31m# Return tensor including `_keras_history`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, batch_size, dtype, input_tensor, sparse, name, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    197\u001b[0m       \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         input_tensor = backend.placeholder(\n\u001b[0m\u001b[0;32m    200\u001b[0m             \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_input_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mplaceholder\u001b[1;34m(shape, ndim, dtype, sparse, name, ragged)\u001b[0m\n\u001b[0;32m   1346\u001b[0m           shape=shape, dtype=dtype, ragged_rank=ragged_rank)\n\u001b[0;32m   1347\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m       spec = tensor_spec.TensorSpec(\n\u001b[0m\u001b[0;32m   1349\u001b[0m           shape=shape, dtype=dtype, name=name)\n\u001b[0;32m   1350\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras_tensor_from_type_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, shape, dtype, name)\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[1;32mnot\u001b[0m \u001b[0mconvertible\u001b[0m \u001b[0mto\u001b[0m \u001b[0ma\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDType\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \"\"\"\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dims)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \"\"\"\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Most common case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    763\u001b[0m     \"\"\"\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Most common case.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mDimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdims\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__index__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m         six.raise_from(\n\u001b[0m\u001b[0;32m    207\u001b[0m             TypeError(\"Dimension value must be integer or None or have \"\n\u001b[0;32m    208\u001b[0m                       \u001b[1;34m\"an __index__ method, got value '{0!r}' with type '{1!r}'\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Dimension value must be integer or None or have an __index__ method, got value '<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_8')>' with type '<class 'keras.engine.keras_tensor.KerasTensor'>'"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(15, activation = \"relu\", input_shape=in_layers))\n",
    "model.add(keras.layers.Dense(10, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(1, activation = \"sigmoid\"))\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "748d8732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_8')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_9')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_10')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_11')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_12')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_13')>,\n",
       " <KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'input_14')>]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a505791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
